{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading covid-19-nlp-text-classification.zip to Datasets_Collection/Coronavirus_Tweets_Classification\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/4.38M [00:00<?, ?B/s]\n",
      " 23%|██▎       | 1.00M/4.38M [00:01<00:05, 644kB/s]\n",
      " 46%|████▌     | 2.00M/4.38M [00:01<00:02, 1.18MB/s]\n",
      " 68%|██████▊   | 3.00M/4.38M [00:02<00:00, 1.66MB/s]\n",
      " 91%|█████████▏| 4.00M/4.38M [00:02<00:00, 2.12MB/s]\n",
      "100%|██████████| 4.38M/4.38M [00:02<00:00, 1.72MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d datatattle/covid-19-nlp-text-classification -p Datasets_Collection/Coronavirus_Tweets_Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(os.getcwd(), \"Datasets_Collection\", \"Coronavirus_Tweets_Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_found = False\n",
    "for filename in os.listdir(dataset_dir):\n",
    "    if filename.endswith(\".zip\"):\n",
    "        dataset_zip_name = filename\n",
    "        zip_found = True\n",
    "        break\n",
    "\n",
    "if not zip_found:\n",
    "    raise FileNotFoundError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(os.path.join(dataset_dir, dataset_zip_name), 'r') as zip_ref:\n",
    "    zip_ref.extractall(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(dataset_dir, \"Corona_NLP_train.csv\"), encoding = \"ISO-8859-1\")\n",
    "test_df = pd.read_csv(os.path.join(dataset_dir, \"Corona_NLP_test.csv\"), encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      UserName  ScreenName             Location     TweetAt  \\\n",
      "0            1       44953                  NYC  02-03-2020   \n",
      "1            2       44954          Seattle, WA  02-03-2020   \n",
      "2            3       44955                  NaN  02-03-2020   \n",
      "3            4       44956          Chicagoland  02-03-2020   \n",
      "4            5       44957  Melbourne, Victoria  03-03-2020   \n",
      "...        ...         ...                  ...         ...   \n",
      "3793      3794       48746            Israel ??  16-03-2020   \n",
      "3794      3795       48747       Farmington, NM  16-03-2020   \n",
      "3795      3796       48748        Haverford, PA  16-03-2020   \n",
      "3796      3797       48749                  NaN  16-03-2020   \n",
      "3797      3798       48750  Arlington, Virginia  16-03-2020   \n",
      "\n",
      "                                          OriginalTweet           Sentiment  \n",
      "0     TRENDING: New Yorkers encounter empty supermar...  Extremely Negative  \n",
      "1     When I couldn't find hand sanitizer at Fred Me...            Positive  \n",
      "2     Find out how you can protect yourself and love...  Extremely Positive  \n",
      "3     #Panic buying hits #NewYork City as anxious sh...            Negative  \n",
      "4     #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral  \n",
      "...                                                 ...                 ...  \n",
      "3793  Meanwhile In A Supermarket in Israel -- People...            Positive  \n",
      "3794  Did you panic buy a lot of non-perishable item...            Negative  \n",
      "3795  Asst Prof of Economics @cconces was on @NBCPhi...             Neutral  \n",
      "3796  Gov need to do somethings instead of biar je r...  Extremely Negative  \n",
      "3797  I and @ForestandPaper members are committed to...  Extremely Positive  \n",
      "\n",
      "[3798 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
